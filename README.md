# Transformers_math_tasks
Проект: Классификация математических задач с использованием трансформеров:

Разработал и обучил классификационную модель для задач на русском языке с использованием архитектуры трансформеров.
Реализовал кастомный класс TransformerClassificationModel на PyTorch с поддержкой выбора любого предобученного backbone-моделя через HuggingFace Transformers.
Использовал модели cointegrated/rubert-tiny2 и tbs17/MathBert как базовые трансформеры; провел дообучение моделей на специализированном датасете.
Реализовал пайплайн: предобработка данных, обучение, валидация, и визуализация результатов, включая графики метрик.
Разработал функцию визуализации карт внимания (attention maps) первого слоя модели, с возможностью интерпретации внимания отдельных attention-head'ов.
Сравнил производительность моделей в замороженном и размороженном режимах (fine-tuning), проанализировал поведение внимания до и после обучения.
Использовал matplotlib, sklearn и seaborn для визуализации обучения, метрик качества и внимания.
